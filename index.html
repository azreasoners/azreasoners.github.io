<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Learning to Solve Constraint Satisfaction Problems with Recurrent Transformers</title>
<link href="style.css" rel="stylesheet">
</head>

<body>
<div class="content">
  <h1>Learning to Solve Constraint Satisfaction Problems with Recurrent Transformers</h1>

  <p id="authors"> <a href="#">Author1<sup>* 1,2</sup></a> <a href="#">Author2<sup>* 1,2</sup></a> <a href="#">Author3<sup>1</sup></a>  <br>

  <span style="font-size: 16px"><br>
      <sup>1</sup>Arizona State University <sup>2</sup> Samsung <br>
   <!-- <sup>*</sup>Denotes Equal Contribution</span> -->
      </p>

  <br>
  <!-- <img src="./images/recurrence.PNG" class="summary-img" style="width:65%;"><br>-->
  <img src="./images/visual_sudoku.PNG" class="summary-img" style="width:70%;"><br>

    <font size="+2">
          <p style="text-align: center;">
              <a href="https://openreview.net/pdf?id=udNhDCr2KQe">Paper</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/azreasoners/recurrent_transformer">Code </a>
          </p>
    </font>
</div>



<div class="content">
  <h2 style="text-align:center;">Abstract</h2>
  <p> Constraint satisfaction problems (CSPs) are about finding values of variables that satisfy the given constraints. We show that the Transformer model extended with recurrence is a viable approach to learning to solve CSPs in an end-to-end manner, having clear advantages over the  state-of-the-art methods such as Graph Neural Networks, SATNet, and some neuro-symbolic models. With the ability of Transformers to handle visual input, the proposed Recurrent Transformer can straightforwardly be applied to visual constraint reasoning problems while successfully addressing the symbol grounding problem. We also show how to leverage deductive knowledge of discrete constraints in the Transformer's inductive learning to achieve sample-efficient learning and semi-supervised learning for CSPs.</p>
</div>


<div class="content">


  <h2>Recurrence</h2>
     <p>


<img class="summary-img" src="./images/recurrence.PNG" style="width:50%;"><br>
We use a recurrent encoder-only model without masking attention. The unrestricted attention allows the any element to pay attention to any other element, and the recurrence encourages a general reasoning algorithm to be learned.    <p>



</div>



<div class="content">
    <h2>Grounding Visual Sudoku</h2>
    <p>
        <img class="summary-img" src="./images/datasets.PNG" style="width:50%;"><br>
        We use the ungrounded visual Sudoku dataset (right) which does not leak any supervision of given Sudoku elements. This means that the recurrent transformer must ground the Sudoku element images using just the solution.‚Äù (last row).<br><br>


        <img class="summary-img" src="./images/visual_sudoku.PNG" style="width:50%;"><br>



  We feed eighty-one 28x28 pixel images of a Sudoku board into the recurrent transformer, which has a small convolutional neural network in the embedding layer.
    </p>
</div>

<div class="content">
      <h2>Results</h2>
    <p>
        <img class="summary-img" src="./images/main_table.PNG" style="width:70%;"><br>
        We achieve state-of-the-art performance in both textual Sudoku and visual Sudoku. We also apply our method to 16x16 textual Sudoku, Shortest Path, and Nonograms (see paper for more details).
  </p>
</div>

<div class="content">
    <h2>Analysis</h2>
    <p>
        <img class="summary-img" src="./images/attention.PNG" style="width:60%;"><br>
        We can plot the learn attention scores for some board which represent row, column and box constraints associated with Sudoku. These constraints are captured with 3 heads, while when training with only one head, some the constraints are combined into one head.

        <img class="summary-img" src="./images/recurrent_steps.PNG" style="width:50%;"><br>
        Adding more recurrent steps, even more than what was trained for gives better performance. This model was trained with 32 recurrent steps, but during inference we can apply more steps (up to 64 shown here). The number of recurrences required is proportional to the hardness of the problem, with the easier boards with more givens not needing as many steps and the harder boards needing increasingly more.
  </p>
</div>

<div class="content">
    <h2>Straight-Through Estimators (STE)</h2>
    <p>
        <img class="summary-img" src="./images/sudoku_ste.PNG" style="width:60%;"><br>
        <img class="summary-img" src="./images/attention_ste.PNG" style="width:35%;"><br>
        We inject constraints into the recurrent transformer using straight-through estimators. Additionally we add attention constraints.
        <img class="summary-img" src="./images/combined_ste.PNG" style="width:65%;"><br>

        We combine this into a constraint loss and get improvements combining them with the supervision loss (left) and using the constraint loss with unlabeled data provides a performance increase in a semi-supervised setting.

        <img class="summary-img" src="./images/ste_results.PNG" style="width:80%;"><br>

  </p>
</div>

</body>
</html>
